{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"X-ray to Volume Registration","text":"<p>Training patient-specific 2D/3D registration models in 5 minutes</p> <ul> <li>\ud83d\ude80 A single CLI/API for training models and registering clinical data</li> <li>\u26a1\ufe0f 100x faster patient-specific model training than <code>DiffPose</code></li> <li>\ud83d\udcd0 Submillimeter registration accuracy with new image similarity metrics</li> <li>\ud83e\udded Human-interpretable pose parameters for training your own models</li> <li>\ud83d\udc0d Pure Python/PyTorch implementation</li> <li>\ud83d\udcbe Supports macOS, Linux, and Windows</li> </ul> <p>Manuscript</p> <p>Vivek Gopalakrishnan, Neel Dey, David-Dimitris Chlorogiannis, Andrew Abumoussa, Anna M. Larson, Darren B. Orbach, Sarah Frisken, and Polina Golland. Rapid patient-specific neural networks for intraoperative X-ray to volume registration. ArXiv (2025): arXiv-2503.</p>"},{"location":"cli/animate/","title":"animate","text":"<p>Animate the trajectory of iterative optimization.</p> <p>Usage:</p> <pre><code>animate [OPTIONS]\n</code></pre> <p>Options:</p> <pre><code>  -i, --inpath PATH   Saved registration result from &lt;xvr register&gt;\n                      [required]\n  -o, --outpath PATH  Savepath for iterative optimization animation\n                      [required]\n  --skip INTEGER      Animate every &lt;skip&gt; frames of the optimization\n                      [default: 1]\n  --dpi INTEGER       DPI of individual animation frames  [default: 192]\n  --fps INTEGER       FPS of animation  [default: 30]\n  -h, --help          Show this message and exit.\n</code></pre>"},{"location":"cli/dcm2nii/","title":"dcm2nii","text":"<p>Convert a DICOMDIR to a NIfTI file.</p> <p>Usage:</p> <pre><code>dcm2nii [OPTIONS] INPATH OUTPATH\n</code></pre> <p>Options:</p> <pre><code>  -h, --help  Show this message and exit.\n</code></pre>"},{"location":"cli/register/","title":"register","text":"<p>Use gradient-based optimization to register XRAY to a CT/MR.</p> <p>XRAY can be a space-separated list of DICOM files or a directory.</p> <p>Usage:</p> <pre><code>register [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <pre><code>  -h, --help  Show this message and exit.\n</code></pre>"},{"location":"cli/register/#dicom","title":"dicom","text":"<p>Initialize from pose parameters in the DICOM header.</p> <p>Usage:</p> <pre><code>register dicom [OPTIONS] XRAY...\n</code></pre> <p>Options:</p> <pre><code>  --orientation [AP|PA]          Orientation of the C-arm  [required]\n  -v, --volume PATH              Input CT volume (3D image)  [required]\n  -m, --mask PATH                Labelmap for the CT volume\n  -o, --outpath PATH             Directory for saving registration results\n                                 [required]\n  --crop INTEGER                 Center crop the X-ray image  [default: 0]\n  --subtract_background          Subtract mode X-ray image intensity\n  --linearize                    Convert X-ray from exponential to linear form\n  --equalize                     Apply histogram equalization to X-rays/DRRs\n                                 during optimization\n  --reducefn TEXT                If DICOM is multiframe, method to extract a\n                                 single 2D image  [default: max]\n  --labels TEXT                  Labels in mask to exclusively render (comma-\n                                 separated)\n  --scales TEXT                  Scales of downsampling for multiscale\n                                 registration (comma-separated)  [default: 8]\n  --n_itrs TEXT                  Number of iterations to run at each scale\n                                 (comma-separated)  [default: 500]\n  --reverse_x_axis               Enable to obey radiologic convention (e.g.,\n                                 heart on right)\n  --renderer [siddon|trilinear]  Renderer equation  [default: trilinear]\n  --parameterization TEXT        Parameterization of SO(3) for regression\n                                 [default: euler_angles]\n  --convention TEXT              If parameterization is Euler angles, specify\n                                 order  [default: ZXY]\n  --voxel_shift FLOAT            Position of voxel (top left corner or center)\n                                 [default: 0.0]\n  --lr_rot FLOAT                 Initial step size for rotational parameters\n                                 [default: 0.01]\n  --lr_xyz FLOAT                 Initial step size for translational\n                                 parameters  [default: 1.0]\n  --patience INTEGER             Number of itrs without improvement before\n                                 decreasing the learning rate  [default: 10]\n  --threshold FLOAT              Threshold for measuring the new optimum\n                                 [default: 0.0001]\n  --max_n_plateaus INTEGER       Number of times loss can plateau before\n                                 moving to next scale  [default: 3]\n  --init_only                    Directly return the initial pose estimate (no\n                                 iterative pose refinement)\n  --saveimg                      Save ground truth X-ray and predicted DRRs\n  --pattern TEXT                 Pattern rule for glob is XRAY is directory\n                                 [default: *.dcm]\n  --verbose INTEGER RANGE        Verbosity level for logging  [default: 1;\n                                 0&lt;=x&lt;=3]\n  -h, --help                     Show this message and exit.\n</code></pre>"},{"location":"cli/register/#fixed","title":"fixed","text":"<p>Initialize from a fixed pose.</p> <p>Usage:</p> <pre><code>register fixed [OPTIONS] XRAY...\n</code></pre> <p>Options:</p> <pre><code>  --orientation [AP|PA]          Orientation of the C-arm  [required]\n  --rot TEXT                     Rotation (comma-separated); see\n                                 `parameterization` and `convention`\n                                 [required]\n  --xyz TEXT                     Translation (comma-separated); see\n                                 `parameterization` and `convention`\n                                 [required]\n  -v, --volume PATH              Input CT volume (3D image)  [required]\n  -m, --mask PATH                Labelmap for the CT volume\n  -o, --outpath PATH             Directory for saving registration results\n                                 [required]\n  --crop INTEGER                 Center crop the X-ray image  [default: 0]\n  --subtract_background          Subtract mode X-ray image intensity\n  --linearize                    Convert X-ray from exponential to linear form\n  --equalize                     Apply histogram equalization to X-rays/DRRs\n                                 during optimization\n  --reducefn TEXT                If DICOM is multiframe, method to extract a\n                                 single 2D image  [default: max]\n  --labels TEXT                  Labels in mask to exclusively render (comma-\n                                 separated)\n  --scales TEXT                  Scales of downsampling for multiscale\n                                 registration (comma-separated)  [default: 8]\n  --n_itrs TEXT                  Number of iterations to run at each scale\n                                 (comma-separated)  [default: 500]\n  --reverse_x_axis               Enable to obey radiologic convention (e.g.,\n                                 heart on right)\n  --renderer [siddon|trilinear]  Renderer equation  [default: trilinear]\n  --parameterization TEXT        Parameterization of SO(3) for regression\n                                 [default: euler_angles]\n  --convention TEXT              If parameterization is Euler angles, specify\n                                 order  [default: ZXY]\n  --voxel_shift FLOAT            Position of voxel (top left corner or center)\n                                 [default: 0.0]\n  --lr_rot FLOAT                 Initial step size for rotational parameters\n                                 [default: 0.01]\n  --lr_xyz FLOAT                 Initial step size for translational\n                                 parameters  [default: 1.0]\n  --patience INTEGER             Number of itrs without improvement before\n                                 decreasing the learning rate  [default: 10]\n  --threshold FLOAT              Threshold for measuring the new optimum\n                                 [default: 0.0001]\n  --max_n_plateaus INTEGER       Number of times loss can plateau before\n                                 moving to next scale  [default: 3]\n  --init_only                    Directly return the initial pose estimate (no\n                                 iterative pose refinement)\n  --saveimg                      Save ground truth X-ray and predicted DRRs\n  --pattern TEXT                 Pattern rule for glob is XRAY is directory\n                                 [default: *.dcm]\n  --verbose INTEGER RANGE        Verbosity level for logging  [default: 1;\n                                 0&lt;=x&lt;=3]\n  -h, --help                     Show this message and exit.\n</code></pre>"},{"location":"cli/register/#model","title":"model","text":"<p>Initialize from a pose regression model.</p> <p>Usage:</p> <pre><code>register model [OPTIONS] XRAY...\n</code></pre> <p>Options:</p> <pre><code>  -c, --ckptpath PATH            Checkpoint of a pretrained pose regressor\n                                 [required]\n  --warp PATH                    SimpleITK transform to warp input CT to a\n                                 template reference frame\n  --invert                       Whether to invert the warp or not\n  --antipodal                    Initialize from antipode of predicted pose\n  -v, --volume PATH              Input CT volume (3D image)  [required]\n  -m, --mask PATH                Labelmap for the CT volume\n  -o, --outpath PATH             Directory for saving registration results\n                                 [required]\n  --crop INTEGER                 Center crop the X-ray image  [default: 0]\n  --subtract_background          Subtract mode X-ray image intensity\n  --linearize                    Convert X-ray from exponential to linear form\n  --equalize                     Apply histogram equalization to X-rays/DRRs\n                                 during optimization\n  --reducefn TEXT                If DICOM is multiframe, method to extract a\n                                 single 2D image  [default: max]\n  --labels TEXT                  Labels in mask to exclusively render (comma-\n                                 separated)\n  --scales TEXT                  Scales of downsampling for multiscale\n                                 registration (comma-separated)  [default: 8]\n  --n_itrs TEXT                  Number of iterations to run at each scale\n                                 (comma-separated)  [default: 500]\n  --reverse_x_axis               Enable to obey radiologic convention (e.g.,\n                                 heart on right)\n  --renderer [siddon|trilinear]  Renderer equation  [default: trilinear]\n  --parameterization TEXT        Parameterization of SO(3) for regression\n                                 [default: euler_angles]\n  --convention TEXT              If parameterization is Euler angles, specify\n                                 order  [default: ZXY]\n  --voxel_shift FLOAT            Position of voxel (top left corner or center)\n                                 [default: 0.0]\n  --lr_rot FLOAT                 Initial step size for rotational parameters\n                                 [default: 0.01]\n  --lr_xyz FLOAT                 Initial step size for translational\n                                 parameters  [default: 1.0]\n  --patience INTEGER             Number of itrs without improvement before\n                                 decreasing the learning rate  [default: 10]\n  --threshold FLOAT              Threshold for measuring the new optimum\n                                 [default: 0.0001]\n  --max_n_plateaus INTEGER       Number of times loss can plateau before\n                                 moving to next scale  [default: 3]\n  --init_only                    Directly return the initial pose estimate (no\n                                 iterative pose refinement)\n  --saveimg                      Save ground truth X-ray and predicted DRRs\n  --pattern TEXT                 Pattern rule for glob is XRAY is directory\n                                 [default: *.dcm]\n  --verbose INTEGER RANGE        Verbosity level for logging  [default: 1;\n                                 0&lt;=x&lt;=3]\n  -h, --help                     Show this message and exit.\n</code></pre>"},{"location":"cli/register/#restart","title":"restart","text":"<p>Initialize from a previous final pose estimate.</p> <p>Usage:</p> <pre><code>register restart [OPTIONS] XRAY...\n</code></pre> <p>Options:</p> <pre><code>  --orientation [AP|PA]          Orientation of the C-arm  [required]\n  -c, --ckpt PATH                Path to `parameters.pt` for previous\n                                 iterative optimization run  [required]\n  -v, --volume PATH              Input CT volume (3D image)  [required]\n  -m, --mask PATH                Labelmap for the CT volume\n  -o, --outpath PATH             Directory for saving registration results\n                                 [required]\n  --crop INTEGER                 Center crop the X-ray image  [default: 0]\n  --subtract_background          Subtract mode X-ray image intensity\n  --linearize                    Convert X-ray from exponential to linear form\n  --equalize                     Apply histogram equalization to X-rays/DRRs\n                                 during optimization\n  --reducefn TEXT                If DICOM is multiframe, method to extract a\n                                 single 2D image  [default: max]\n  --labels TEXT                  Labels in mask to exclusively render (comma-\n                                 separated)\n  --scales TEXT                  Scales of downsampling for multiscale\n                                 registration (comma-separated)  [default: 8]\n  --n_itrs TEXT                  Number of iterations to run at each scale\n                                 (comma-separated)  [default: 500]\n  --reverse_x_axis               Enable to obey radiologic convention (e.g.,\n                                 heart on right)\n  --renderer [siddon|trilinear]  Renderer equation  [default: trilinear]\n  --parameterization TEXT        Parameterization of SO(3) for regression\n                                 [default: euler_angles]\n  --convention TEXT              If parameterization is Euler angles, specify\n                                 order  [default: ZXY]\n  --voxel_shift FLOAT            Position of voxel (top left corner or center)\n                                 [default: 0.0]\n  --lr_rot FLOAT                 Initial step size for rotational parameters\n                                 [default: 0.01]\n  --lr_xyz FLOAT                 Initial step size for translational\n                                 parameters  [default: 1.0]\n  --patience INTEGER             Number of itrs without improvement before\n                                 decreasing the learning rate  [default: 10]\n  --threshold FLOAT              Threshold for measuring the new optimum\n                                 [default: 0.0001]\n  --max_n_plateaus INTEGER       Number of times loss can plateau before\n                                 moving to next scale  [default: 3]\n  --init_only                    Directly return the initial pose estimate (no\n                                 iterative pose refinement)\n  --saveimg                      Save ground truth X-ray and predicted DRRs\n  --pattern TEXT                 Pattern rule for glob is XRAY is directory\n                                 [default: *.dcm]\n  --verbose INTEGER RANGE        Verbosity level for logging  [default: 1;\n                                 0&lt;=x&lt;=3]\n  -h, --help                     Show this message and exit.\n</code></pre>"},{"location":"cli/restart/","title":"restart","text":"<p>Restart model training from a checkpoint.</p> <p>Usage:</p> <pre><code>restart [OPTIONS]\n</code></pre> <p>Options:</p> <pre><code>  -c, --ckptpath PATH  Checkpoint of a pretrained pose regressor  [required]\n  --id TEXT            WandB run ID\n  --project TEXT       WandB project name\n  -h, --help           Show this message and exit.\n</code></pre>"},{"location":"cli/train/","title":"train","text":"<p>Train a pose regression model.</p> <p>Usage:</p> <pre><code>train [OPTIONS]\n</code></pre> <p>Options:</p> <pre><code>  -v, --volpath PATH              A single CT or a directory with multiple\n                                  volumes for pretraining  [required]\n  -m, --maskpath PATH             Optional labelmaps corresponding to the CTs\n                                  passed in `volpath`\n  -c, --ckptpath PATH             Checkpoint of a pretrained pose regressor\n  -o, --outpath PATH              Directory in which to save model weights\n                                  [required]\n  --r1 &lt;FLOAT FLOAT&gt;...           Range for primary angle (in degrees)\n                                  [required]\n  --r2 &lt;FLOAT FLOAT&gt;...           Range for secondary angle (in degrees)\n                                  [required]\n  --r3 &lt;FLOAT FLOAT&gt;...           Range for tertiary angle (in degrees)\n                                  [required]\n  --tx &lt;FLOAT FLOAT&gt;...           Range for x-offset (in millimeters)\n                                  [required]\n  --ty &lt;FLOAT FLOAT&gt;...           Range for y-offset (in millimeters)\n                                  [required]\n  --tz &lt;FLOAT FLOAT&gt;...           Range for z-offset (in millimeters)\n                                  [required]\n  --sdd FLOAT                     Source-to-detector distance (in millimeters)\n                                  [required]\n  --height INTEGER                DRR height (in pixels)  [required]\n  --delx FLOAT                    DRR pixel size (in millimeters / pixel)\n                                  [required]\n  --renderer [siddon|trilinear]   Rendering equation  [default: trilinear]\n  --orientation [AP|PA]           Orientation of CT volumes  [default: AP]\n  --reverse_x_axis                Enable to obey radiologic convention (e.g.,\n                                  heart on right)\n  --model_name TEXT               Name of model to instantiate from the timm\n                                  library  [default: resnet18]\n  --norm_layer TEXT               Normalization layer  [default: groupnorm]\n  --pretrained                    Load pretrained ImageNet-1k weights\n  --parameterization TEXT         Parameterization of SO(3) for regression\n                                  [default: quaternion_adjugate]\n  --convention TEXT               If `parameterization='euler_angles'`,\n                                  specify order  [default: ZXY]\n  --unit_conversion_factor FLOAT  Scale factor for translation prediction\n                                  (e.g., from m to mm)  [default: 1000.0]\n  --p_augmentation FLOAT          Base probability of image augmentations\n                                  during training  [default: 0.333]\n  --lr FLOAT                      Maximum learning rate  [default: 0.0002]\n  --weight_ncc FLOAT              Weight on mNCC loss term  [default: 1.0]\n  --weight_geo FLOAT              Weight on geodesic loss term  [default:\n                                  0.01]\n  --weight_dice FLOAT             Weight on Dice loss term  [default: 1.0]\n  --weight_mvc FLOAT              Weight on multiview consistency loss term\n                                  [default: 0]\n  --batch_size INTEGER            Number of DRRs per batch  [default: 116]\n  --n_total_itrs INTEGER          Number of iterations for training the model\n                                  [default: 1000000]\n  --n_warmup_itrs INTEGER         Number of iterations for warming up the\n                                  learning rate  [default: 1000]\n  --n_grad_accum_itrs INTEGER     Number of iterations for gradient\n                                  accumulation  [default: 4]\n  --n_save_every_itrs INTEGER     Number of iterations before saving a new\n                                  model checkpoint  [default: 1000]\n  --disable_scheduler             Turn off cosine learning rate scheduler\n  --reuse_optimizer               If ckptpath passed, initialize the previous\n                                  optimizer's state\n  -w, --warp PATH                 SimpleITK transform to warp input CT to the\n                                  checkpoint's reference frame\n  --invert                        Whether to invert the warp or not\n  --patch_size TEXT               Optional random crop size (e.g., 'h,w,d');\n                                  if None, return entire volume\n  --num_workers INTEGER           Number of subprocesses to use in the\n                                  dataloader  [default: 4]\n  --pin_memory                    Copy volumes from the dataloader into CUDA\n                                  pinned memory before returning\n  --sample_weights PATH           Probability for sampling each volume in\n                                  `volpath`\n  --name TEXT                     WandB run name\n  --id TEXT                       WandB run ID (useful when restarting from a\n                                  checkpoint)\n  --project TEXT                  WandB project name  [default: xvr]\n  -h, --help                      Show this message and exit.\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>cli<ul> <li>cli</li> <li>commands<ul> <li>animate</li> <li>dcm2nii</li> <li>register</li> <li>restart</li> <li>train</li> </ul> </li> <li>formatter</li> </ul> </li> <li>config<ul> <li>registrar</li> <li>trainer</li> </ul> </li> <li>io<ul> <li>xray</li> </ul> </li> <li>metrics<ul> <li>evaluator</li> </ul> </li> <li>model<ul> <li>augmentations</li> <li>inference</li> <li>loss</li> <li>network</li> <li>sampler</li> <li>scheduler</li> <li>trainer</li> <li>utils</li> </ul> </li> <li>registrar<ul> <li>base</li> <li>dicom</li> <li>fixed</li> <li>model</li> <li>restart</li> </ul> </li> <li>renderer<ul> <li>load</li> </ul> </li> <li>utils<ul> <li>ants</li> <li>preprocess</li> </ul> </li> <li>visualization<ul> <li>animate</li> <li>viz2d</li> </ul> </li> </ul>"},{"location":"reference/xvr/cli/","title":"cli","text":""},{"location":"reference/xvr/cli/#xvr.cli","title":"xvr.cli","text":""},{"location":"reference/xvr/cli/cli/","title":"cli","text":""},{"location":"reference/xvr/cli/cli/#xvr.cli.cli","title":"xvr.cli.cli","text":""},{"location":"reference/xvr/cli/cli/#xvr.cli.cli.register","title":"register","text":"<pre><code>register()\n</code></pre> <p>Use gradient-based optimization to register XRAY to a CT/MR.</p> <p>XRAY can be a space-separated list of DICOM files or a directory.</p> Source code in <code>src/xvr/cli/cli.py</code> <pre><code>@click.group(cls=OrderedGroup)\ndef register():\n    \"\"\"\n    Use gradient-based optimization to register XRAY to a CT/MR.\n\n    XRAY can be a space-separated list of DICOM files or a directory.\n    \"\"\"\n</code></pre>"},{"location":"reference/xvr/cli/cli/#xvr.cli.cli.cli","title":"cli","text":"<pre><code>cli(ctx)\n</code></pre> <p>A PyTorch package for 2D/3D XRAY to CT/MR registration.</p> <p>Provides functionality for rapidly training pose regression models and registering clinical data with gradient-based iterative optimization.</p> Source code in <code>src/xvr/cli/cli.py</code> <pre><code>@click.group(cls=OrderedGroup)\n@click.version_option(version(\"xvr\"), \"--version\", \"-v\")\n@click.pass_context\ndef cli(ctx):\n    \"\"\"\n    A PyTorch package for 2D/3D XRAY to CT/MR registration.\n\n    Provides functionality for rapidly training pose regression models and\n    registering clinical data with gradient-based iterative optimization.\n    \"\"\"\n</code></pre>"},{"location":"reference/xvr/cli/formatter/","title":"formatter","text":""},{"location":"reference/xvr/cli/formatter/#xvr.cli.formatter","title":"xvr.cli.formatter","text":""},{"location":"reference/xvr/cli/formatter/#xvr.cli.formatter.CategorizedCommand","title":"CategorizedCommand","text":"<pre><code>CategorizedCommand(category_order=[], *args, **kwargs)\n</code></pre> <p>Click Command with support for categorized parameters.</p> Source code in <code>src/xvr/cli/formatter.py</code> <pre><code>def __init__(self, category_order=[], *args, **kwargs):\n    # Set default context settings\n    kwargs[\"context_settings\"] = {\n        \"show_default\": True,\n        \"max_content_width\": 120,\n        \"help_option_names\": [\"-h\", \"--help\"],\n    }\n    super().__init__(*args, **kwargs)\n\n    # Get categories to use as section headers in the help page\n    self.category_order = category_order + [\"Miscellaneous\"]\n</code></pre>"},{"location":"reference/xvr/cli/formatter/#xvr.cli.formatter.CategorizedCommand.format_help","title":"format_help","text":"<pre><code>format_help(ctx, formatter)\n</code></pre> <p>Format help using categorized display.</p> Source code in <code>src/xvr/cli/formatter.py</code> <pre><code>def format_help(self, ctx, formatter):\n    \"\"\"Format help using categorized display.\"\"\"\n    format_categorized_help(self, ctx, formatter, self.category_order)\n</code></pre>"},{"location":"reference/xvr/cli/formatter/#xvr.cli.formatter.CategorizedOption","title":"CategorizedOption","text":"<pre><code>CategorizedOption(*args, category='Miscellaneous', **kwargs)\n</code></pre> <p>Click Option with category support for grouped help display.</p> Source code in <code>src/xvr/cli/formatter.py</code> <pre><code>def __init__(self, *args, category=\"Miscellaneous\", **kwargs):\n    self.category = category\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/xvr/cli/formatter/#xvr.cli.formatter.format_categorized_help","title":"format_categorized_help","text":"<pre><code>format_categorized_help(command, ctx, formatter, category_order: list)\n</code></pre> <p>Format help output with parameters grouped by category using Click's default formatting.</p> Source code in <code>src/xvr/cli/formatter.py</code> <pre><code>def format_categorized_help(command, ctx, formatter, category_order: list):\n    \"\"\"Format help output with parameters grouped by category using Click's default formatting.\"\"\"\n\n    # Use Click's default usage and description formatting\n    command.format_usage(ctx, formatter)\n    if command.help:\n        formatter.indent()\n        formatter.write_paragraph()\n        formatter.write_text(command.help)\n        formatter.dedent()\n\n    # Group parameters by category\n    categories = defaultdict(list)\n    for param in command.params:\n        if isinstance(param, click.Argument):\n            continue\n        category = getattr(param, \"category\", \"Miscellaneous\")\n        categories[category].append(param)\n\n    # Collect all help records first to calculate consistent spacing\n    all_rows = []\n    category_sections = []\n\n    for category in category_order:\n        params = categories.get(category, [])\n        if not params:\n            continue\n\n        rows = []\n        for param in params:\n            rv = param.get_help_record(ctx)\n            rows.append(rv)\n\n        if rows:\n            section_name = f\"{category} options\" if len(categories) &gt; 1 else \"Options\"\n            category_sections.append((section_name, rows))\n            all_rows.extend(rows)\n\n    # Calculate the maximum width needed across all categories\n    # And print each parameter description with consistent spacing\n    if all_rows:\n        max_width = max(len(row[0]) for row in all_rows)\n        for section_name, rows in category_sections:\n            with formatter.section(section_name):\n                for parameter, docstring in rows:\n                    formatter.write_text(f\"{parameter:&lt;{max_width}}  {docstring}\")\n</code></pre>"},{"location":"reference/xvr/cli/formatter/#xvr.cli.formatter.categorized_option","title":"categorized_option","text":"<pre><code>categorized_option(*param_decls, category='Miscellaneous', **kwargs)\n</code></pre> <p>Decorator to add a categorized option to a command.</p> Source code in <code>src/xvr/cli/formatter.py</code> <pre><code>def categorized_option(*param_decls, category=\"Miscellaneous\", **kwargs):\n    \"\"\"Decorator to add a categorized option to a command.\"\"\"\n\n    def decorator(f):\n        if not hasattr(f, \"__click_params__\"):\n            f.__click_params__ = []\n        f.__click_params__.append(\n            CategorizedOption(param_decls, category=category, **kwargs)\n        )\n        return f\n\n    return decorator\n</code></pre>"},{"location":"reference/xvr/cli/commands/","title":"commands","text":""},{"location":"reference/xvr/cli/commands/#xvr.cli.commands","title":"xvr.cli.commands","text":""},{"location":"reference/xvr/cli/commands/animate/","title":"animate","text":""},{"location":"reference/xvr/cli/commands/animate/#xvr.cli.commands.animate","title":"xvr.cli.commands.animate","text":""},{"location":"reference/xvr/cli/commands/animate/#xvr.cli.commands.animate.animate","title":"animate","text":"<pre><code>animate(inpath, outpath, skip, dpi, fps)\n</code></pre> <p>Animate the trajectory of iterative optimization.</p> Source code in <code>src/xvr/cli/commands/animate.py</code> <pre><code>@click.command(cls=CategorizedCommand)\n@categorized_option(\n    \"-i\",\n    \"--inpath\",\n    required=True,\n    type=click.Path(exists=True),\n    help=\"Saved registration result from &lt;xvr register&gt;\",\n)\n@categorized_option(\n    \"-o\",\n    \"--outpath\",\n    required=True,\n    type=click.Path(),\n    help=\"Savepath for iterative optimization animation\",\n)\n@categorized_option(\n    \"--skip\",\n    default=1,\n    type=int,\n    help=\"Animate every &lt;skip&gt; frames of the optimization\",\n)\n@categorized_option(\n    \"--dpi\",\n    default=192,\n    type=int,\n    help=\"DPI of individual animation frames\",\n)\n@categorized_option(\n    \"--fps\",\n    default=30,\n    type=int,\n    help=\"FPS of animation\",\n)\ndef animate(inpath, outpath, skip, dpi, fps):\n    \"\"\"Animate the trajectory of iterative optimization.\"\"\"\n\n    from ...visualization import animate as _animate\n\n    _animate(inpath, outpath, skip, dpi, fps)\n</code></pre>"},{"location":"reference/xvr/cli/commands/dcm2nii/","title":"dcm2nii","text":""},{"location":"reference/xvr/cli/commands/dcm2nii/#xvr.cli.commands.dcm2nii","title":"xvr.cli.commands.dcm2nii","text":""},{"location":"reference/xvr/cli/commands/dcm2nii/#xvr.cli.commands.dcm2nii.dcm2nii","title":"dcm2nii","text":"<pre><code>dcm2nii(inpath, outpath)\n</code></pre> <p>Convert a DICOMDIR to a NIfTI file.</p> Source code in <code>src/xvr/cli/commands/dcm2nii.py</code> <pre><code>@click.command(cls=CategorizedCommand)\n@click.argument(\"inpath\", type=click.Path(exists=True))\n@click.argument(\"outpath\", type=click.Path())\ndef dcm2nii(inpath, outpath):\n    \"\"\"Convert a DICOMDIR to a NIfTI file.\"\"\"\n\n    from torchio import ScalarImage\n\n    click.echo(f\"Converting {inpath} to {outpath}\")\n\n    volume = ScalarImage(inpath)\n    volume.save(outpath)\n</code></pre>"},{"location":"reference/xvr/cli/commands/register/","title":"register","text":""},{"location":"reference/xvr/cli/commands/register/#xvr.cli.commands.register","title":"xvr.cli.commands.register","text":""},{"location":"reference/xvr/cli/commands/register/#xvr.cli.commands.register.model","title":"model","text":"<pre><code>model(\n    xray,\n    volume,\n    mask,\n    outpath,\n    crop,\n    subtract_background,\n    linearize,\n    equalize,\n    reducefn,\n    labels,\n    scales,\n    n_itrs,\n    reverse_x_axis,\n    renderer,\n    parameterization,\n    convention,\n    voxel_shift,\n    lr_rot,\n    lr_xyz,\n    patience,\n    threshold,\n    max_n_plateaus,\n    init_only,\n    saveimg,\n    pattern,\n    verbose,\n    ckptpath,\n    warp,\n    invert,\n    antipodal,\n)\n</code></pre> <p>Initialize from a pose regression model.</p> Source code in <code>src/xvr/cli/commands/register.py</code> <pre><code>@click.command(cls=BaseRegistrar)\n@categorized_option(\n    \"-c\",\n    \"--ckptpath\",\n    required=True,\n    type=click.Path(exists=True),\n    help=\"Checkpoint of a pretrained pose regressor\",\n    category=\"Required\",\n)\n@categorized_option(\n    \"--warp\",\n    type=click.Path(exists=True),\n    help=\"SimpleITK transform to warp input CT to a template reference frame\",\n)\n@categorized_option(\n    \"--invert\",\n    default=False,\n    is_flag=True,\n    help=\"Whether to invert the warp or not\",\n)\n@categorized_option(\n    \"--antipodal\",\n    default=False,\n    is_flag=True,\n    help=\"Initialize from antipode of predicted pose\",\n)\ndef model(\n    xray,\n    volume,\n    mask,\n    outpath,\n    crop,\n    subtract_background,\n    linearize,\n    equalize,\n    reducefn,\n    labels,\n    scales,\n    n_itrs,\n    reverse_x_axis,\n    renderer,\n    parameterization,\n    convention,\n    voxel_shift,\n    lr_rot,\n    lr_xyz,\n    patience,\n    threshold,\n    max_n_plateaus,\n    init_only,\n    saveimg,\n    pattern,\n    verbose,\n    ckptpath,\n    warp,\n    invert,\n    antipodal,\n):\n    \"\"\"Initialize from a pose regression model.\"\"\"\n    from ...registrar import RegistrarModel\n\n    registrar = RegistrarModel(\n        volume,\n        mask,\n        ckptpath,\n        labels,\n        crop,\n        subtract_background,\n        linearize,\n        equalize,\n        reducefn,\n        warp,\n        invert,\n        antipodal,\n        scales,\n        n_itrs,\n        reverse_x_axis,\n        renderer,\n        parameterization,\n        convention,\n        voxel_shift,\n        lr_rot,\n        lr_xyz,\n        patience,\n        threshold,\n        max_n_plateaus,\n        init_only,\n        saveimg,\n        verbose,\n    )\n\n    run(registrar, xray, pattern, verbose, outpath)\n</code></pre>"},{"location":"reference/xvr/cli/commands/register/#xvr.cli.commands.register.dicom","title":"dicom","text":"<pre><code>dicom(\n    xray,\n    volume,\n    mask,\n    outpath,\n    crop,\n    subtract_background,\n    linearize,\n    equalize,\n    reducefn,\n    labels,\n    scales,\n    n_itrs,\n    reverse_x_axis,\n    renderer,\n    parameterization,\n    convention,\n    voxel_shift,\n    lr_rot,\n    lr_xyz,\n    patience,\n    threshold,\n    max_n_plateaus,\n    init_only,\n    saveimg,\n    pattern,\n    verbose,\n    orientation,\n)\n</code></pre> <p>Initialize from pose parameters in the DICOM header.</p> Source code in <code>src/xvr/cli/commands/register.py</code> <pre><code>@click.command(cls=BaseRegistrar)\n@categorized_option(\n    \"--orientation\",\n    required=True,\n    type=click.Choice([\"AP\", \"PA\"]),\n    category=\"Required\",\n    help=\"Orientation of the C-arm\",\n)\ndef dicom(\n    xray,\n    volume,\n    mask,\n    outpath,\n    crop,\n    subtract_background,\n    linearize,\n    equalize,\n    reducefn,\n    labels,\n    scales,\n    n_itrs,\n    reverse_x_axis,\n    renderer,\n    parameterization,\n    convention,\n    voxel_shift,\n    lr_rot,\n    lr_xyz,\n    patience,\n    threshold,\n    max_n_plateaus,\n    init_only,\n    saveimg,\n    pattern,\n    verbose,\n    orientation,\n):\n    \"\"\"Initialize from pose parameters in the DICOM header.\"\"\"\n    from ...registrar import RegistrarDicom\n\n    registrar = RegistrarDicom(\n        volume,\n        mask,\n        orientation,\n        labels,\n        crop,\n        subtract_background,\n        linearize,\n        equalize,\n        scales,\n        n_itrs,\n        reverse_x_axis,\n        renderer,\n        reducefn,\n        parameterization,\n        convention,\n        voxel_shift,\n        lr_rot,\n        lr_xyz,\n        patience,\n        threshold,\n        max_n_plateaus,\n        init_only,\n        saveimg,\n        verbose,\n    )\n\n    run(registrar, xray, pattern, verbose, outpath)\n</code></pre>"},{"location":"reference/xvr/cli/commands/register/#xvr.cli.commands.register.fixed","title":"fixed","text":"<pre><code>fixed(\n    xray,\n    volume,\n    mask,\n    outpath,\n    crop,\n    subtract_background,\n    linearize,\n    equalize,\n    reducefn,\n    labels,\n    scales,\n    n_itrs,\n    reverse_x_axis,\n    renderer,\n    parameterization,\n    convention,\n    voxel_shift,\n    lr_rot,\n    lr_xyz,\n    patience,\n    threshold,\n    max_n_plateaus,\n    init_only,\n    saveimg,\n    pattern,\n    verbose,\n    orientation,\n    rot,\n    xyz,\n)\n</code></pre> <p>Initialize from a fixed pose.</p> Source code in <code>src/xvr/cli/commands/register.py</code> <pre><code>@click.command(cls=BaseRegistrar)\n@categorized_option(\n    \"--orientation\",\n    required=True,\n    type=click.Choice([\"AP\", \"PA\"]),\n    category=\"Required\",\n    help=\"Orientation of the C-arm\",\n)\n@categorized_option(\n    \"--rot\",\n    required=True,\n    type=str,\n    help=\"Rotation (comma-separated); see `parameterization` and `convention`\",\n    category=\"Required\",\n)\n@categorized_option(\n    \"--xyz\",\n    required=True,\n    type=str,\n    help=\"Translation (comma-separated); see `parameterization` and `convention`\",\n    category=\"Required\",\n)\ndef fixed(\n    xray,\n    volume,\n    mask,\n    outpath,\n    crop,\n    subtract_background,\n    linearize,\n    equalize,\n    reducefn,\n    labels,\n    scales,\n    n_itrs,\n    reverse_x_axis,\n    renderer,\n    parameterization,\n    convention,\n    voxel_shift,\n    lr_rot,\n    lr_xyz,\n    patience,\n    threshold,\n    max_n_plateaus,\n    init_only,\n    saveimg,\n    pattern,\n    verbose,\n    orientation,\n    rot,\n    xyz,\n):\n    \"\"\"Initialize from a fixed pose.\"\"\"\n    from ...registrar import RegistrarFixed\n\n    rot = [float(x) for x in rot.split(\",\")]\n    xyz = [float(x) for x in xyz.split(\",\")]\n\n    registrar = RegistrarFixed(\n        volume,\n        mask,\n        orientation,\n        rot,\n        xyz,\n        labels,\n        crop,\n        subtract_background,\n        linearize,\n        equalize,\n        reducefn,\n        scales,\n        n_itrs,\n        reverse_x_axis,\n        renderer,\n        parameterization,\n        convention,\n        voxel_shift,\n        lr_rot,\n        lr_xyz,\n        patience,\n        threshold,\n        max_n_plateaus,\n        init_only,\n        saveimg,\n        verbose,\n    )\n\n    run(registrar, xray, pattern, verbose, outpath)\n</code></pre>"},{"location":"reference/xvr/cli/commands/register/#xvr.cli.commands.register.restart","title":"restart","text":"<pre><code>restart(\n    xray,\n    volume,\n    mask,\n    outpath,\n    crop,\n    subtract_background,\n    linearize,\n    equalize,\n    reducefn,\n    labels,\n    scales,\n    n_itrs,\n    reverse_x_axis,\n    renderer,\n    parameterization,\n    convention,\n    voxel_shift,\n    lr_rot,\n    lr_xyz,\n    patience,\n    threshold,\n    max_n_plateaus,\n    init_only,\n    saveimg,\n    pattern,\n    verbose,\n    orientation,\n    ckpt,\n)\n</code></pre> <p>Initialize from a previous final pose estimate.</p> Source code in <code>src/xvr/cli/commands/register.py</code> <pre><code>@click.command(cls=BaseRegistrar)\n@categorized_option(\n    \"--orientation\",\n    required=True,\n    type=click.Choice([\"AP\", \"PA\"]),\n    category=\"Required\",\n    help=\"Orientation of the C-arm\",\n)\n@categorized_option(\n    \"-c\",\n    \"--ckpt\",\n    required=True,\n    type=click.Path(exists=True),\n    help=\"Path to `parameters.pt` for previous iterative optimization run\",\n    category=\"Required\",\n)\ndef restart(\n    xray,\n    volume,\n    mask,\n    outpath,\n    crop,\n    subtract_background,\n    linearize,\n    equalize,\n    reducefn,\n    labels,\n    scales,\n    n_itrs,\n    reverse_x_axis,\n    renderer,\n    parameterization,\n    convention,\n    voxel_shift,\n    lr_rot,\n    lr_xyz,\n    patience,\n    threshold,\n    max_n_plateaus,\n    init_only,\n    saveimg,\n    pattern,\n    verbose,\n    orientation,\n    ckpt,\n):\n    \"\"\"Initialize from a previous final pose estimate.\"\"\"\n    import torch\n    from diffdrr.pose import RigidTransform\n\n    from ...registrar import RegistrarRestart\n\n    ckpt = torch.load(ckpt, weights_only=False)\n    pose = RigidTransform(ckpt[\"final_pose\"])\n\n    registrar = RegistrarRestart(\n        volume,\n        mask,\n        orientation,\n        pose,\n        labels,\n        crop,\n        subtract_background,\n        linearize,\n        equalize,\n        reducefn,\n        scales,\n        n_itrs,\n        reverse_x_axis,\n        renderer,\n        parameterization,\n        convention,\n        voxel_shift,\n        lr_rot,\n        lr_xyz,\n        patience,\n        threshold,\n        max_n_plateaus,\n        init_only,\n        saveimg,\n        verbose,\n    )\n\n    run(registrar, xray, pattern, verbose, outpath)\n</code></pre>"},{"location":"reference/xvr/cli/commands/restart/","title":"restart","text":""},{"location":"reference/xvr/cli/commands/restart/#xvr.cli.commands.restart","title":"xvr.cli.commands.restart","text":""},{"location":"reference/xvr/cli/commands/restart/#xvr.cli.commands.restart.restart","title":"restart","text":"<pre><code>restart(ckptpath: str, id: str, project: str)\n</code></pre> <p>Restart model training from a checkpoint.</p> Source code in <code>src/xvr/cli/commands/restart.py</code> <pre><code>@click.command(cls=CategorizedCommand)\n@categorized_option(\n    \"-c\",\n    \"--ckptpath\",\n    required=True,\n    type=click.Path(exists=True),\n    help=\"Checkpoint of a pretrained pose regressor\",\n)\n@categorized_option(\n    \"--id\",\n    default=None,\n    type=str,\n    help=\"WandB run ID\",\n)\n@categorized_option(\n    \"--project\",\n    type=str,\n    default=None,\n    help=\"WandB project name\",\n)\ndef restart(\n    ckptpath: str,\n    id: str,\n    project: str,\n):\n    \"\"\"\n    Restart model training from a checkpoint.\n    \"\"\"\n    import os\n    from pathlib import Path\n\n    import torch\n    import wandb\n\n    from ...model import Trainer\n\n    # If ckptpath is a directory, get the last saved model\n    ckptpath = Path(ckptpath)\n    if ckptpath.is_dir():\n        ckptpath = sorted(ckptpath.glob(\"*.pth\"))[-1]\n    ckptpath = str(ckptpath)\n\n    # Load the config from the previous model checkpoint\n    config = torch.load(ckptpath, weights_only=False)[\"config\"]\n    config[\"ckptpath\"] = ckptpath\n    config[\"reuse_optimizer\"] = True\n\n    # Set up logging\n    wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n    project = config[\"project\"] if project is None else project\n    run = wandb.init(project=project, id=id, config=config, resume=\"must\")\n\n    # Train the model\n    trainer = Trainer(**config)\n    trainer.train(run)\n</code></pre>"},{"location":"reference/xvr/cli/commands/train/","title":"train","text":""},{"location":"reference/xvr/cli/commands/train/#xvr.cli.commands.train","title":"xvr.cli.commands.train","text":""},{"location":"reference/xvr/cli/commands/train/#xvr.cli.commands.train.train","title":"train","text":"<pre><code>train(\n    volpath,\n    maskpath,\n    ckptpath,\n    outpath,\n    r1,\n    r2,\n    r3,\n    tx,\n    ty,\n    tz,\n    sdd,\n    height,\n    delx,\n    renderer,\n    orientation,\n    reverse_x_axis,\n    model_name,\n    norm_layer,\n    pretrained,\n    parameterization,\n    convention,\n    unit_conversion_factor,\n    p_augmentation,\n    lr,\n    weight_ncc,\n    weight_geo,\n    weight_dice,\n    weight_mvc,\n    batch_size,\n    n_total_itrs,\n    n_warmup_itrs,\n    n_grad_accum_itrs,\n    n_save_every_itrs,\n    disable_scheduler,\n    reuse_optimizer,\n    warp,\n    invert,\n    patch_size,\n    num_workers,\n    pin_memory,\n    sample_weights,\n    name,\n    id,\n    project,\n)\n</code></pre> <p>Train a pose regression model.</p> Source code in <code>src/xvr/cli/commands/train.py</code> <pre><code>@click.command(\n    cls=CategorizedCommand,\n    category_order=[\n        \"Required\",\n        \"Data\",\n        \"Sampling\",\n        \"Renderer\",\n        \"Model\",\n        \"Optimizer\",\n        \"Checkpoint\",\n        \"Logging\",\n    ],\n)\n@categorized_option(\n    \"-v\",\n    \"--volpath\",\n    required=True,\n    type=click.Path(exists=True),\n    help=\"A single CT or a directory with multiple volumes for pretraining\",\n    category=\"Required\",\n)\n@categorized_option(\n    \"-m\",\n    \"--maskpath\",\n    required=False,\n    type=click.Path(exists=True),\n    help=\"Optional labelmaps corresponding to the CTs passed in `volpath`\",\n    category=\"Data\",\n)\n@categorized_option(\n    \"-c\",\n    \"--ckptpath\",\n    required=False,\n    type=click.Path(exists=True),\n    help=\"Checkpoint of a pretrained pose regressor\",\n    category=\"Checkpoint\",\n)\n@categorized_option(\n    \"-o\",\n    \"--outpath\",\n    required=True,\n    type=click.Path(),\n    help=\"Directory in which to save model weights\",\n    category=\"Required\",\n)\n@categorized_option(\n    \"--r1\",\n    required=True,\n    type=(float, float),\n    help=\"Range for primary angle (in degrees)\",\n    category=\"Sampling\",\n)\n@categorized_option(\n    \"--r2\",\n    required=True,\n    type=(float, float),\n    help=\"Range for secondary angle (in degrees)\",\n    category=\"Sampling\",\n)\n@categorized_option(\n    \"--r3\",\n    required=True,\n    type=(float, float),\n    help=\"Range for tertiary angle (in degrees)\",\n    category=\"Sampling\",\n)\n@categorized_option(\n    \"--tx\",\n    required=True,\n    type=(float, float),\n    help=\"Range for x-offset (in millimeters)\",\n    category=\"Sampling\",\n)\n@categorized_option(\n    \"--ty\",\n    required=True,\n    type=(float, float),\n    help=\"Range for y-offset (in millimeters)\",\n    category=\"Sampling\",\n)\n@categorized_option(\n    \"--tz\",\n    required=True,\n    type=(float, float),\n    help=\"Range for z-offset (in millimeters)\",\n    category=\"Sampling\",\n)\n@categorized_option(\n    \"--sdd\",\n    required=True,\n    type=float,\n    help=\"Source-to-detector distance (in millimeters)\",\n    category=\"Renderer\",\n)\n@categorized_option(\n    \"--height\",\n    required=True,\n    type=int,\n    help=\"DRR height (in pixels)\",\n    category=\"Renderer\",\n)\n@categorized_option(\n    \"--delx\",\n    required=True,\n    type=float,\n    help=\"DRR pixel size (in millimeters / pixel)\",\n    category=\"Renderer\",\n)\n@categorized_option(\n    \"--renderer\",\n    default=args.renderer,\n    type=click.Choice([\"siddon\", \"trilinear\"]),\n    help=\"Rendering equation\",\n    category=\"Renderer\",\n)\n@categorized_option(\n    \"--orientation\",\n    default=args.orientation,\n    type=click.Choice([\"AP\", \"PA\"]),\n    help=\"Orientation of CT volumes\",\n    category=\"Renderer\",\n)\n@categorized_option(\n    \"--reverse_x_axis\",\n    default=args.reverse_x_axis,\n    is_flag=True,\n    help=\"Enable to obey radiologic convention (e.g., heart on right)\",\n    category=\"Renderer\",\n)\n@categorized_option(\n    \"--model_name\",\n    default=args.model_name,\n    type=str,\n    help=\"Name of model to instantiate from the timm library\",\n    category=\"Model\",\n)\n@categorized_option(\n    \"--norm_layer\",\n    default=args.norm_layer,\n    type=str,\n    help=\"Normalization layer\",\n    category=\"Model\",\n)\n@categorized_option(\n    \"--pretrained\",\n    default=args.pretrained,\n    is_flag=True,\n    help=\"Load pretrained ImageNet-1k weights\",\n    category=\"Model\",\n)\n@categorized_option(\n    \"--parameterization\",\n    default=args.parameterization,\n    type=str,\n    help=\"Parameterization of SO(3) for regression\",\n    category=\"Model\",\n)\n@categorized_option(\n    \"--convention\",\n    default=args.convention,\n    type=str,\n    help=\"If `parameterization='euler_angles'`, specify order\",\n    category=\"Model\",\n)\n@categorized_option(\n    \"--unit_conversion_factor\",\n    default=args.unit_conversion_factor,\n    type=float,\n    help=\"Scale factor for translation prediction (e.g., from m to mm)\",\n    category=\"Model\",\n)\n@categorized_option(\n    \"--p_augmentation\",\n    default=args.p_augmentation,\n    type=float,\n    help=\"Base probability of image augmentations during training\",\n    category=\"Model\",\n)\n@categorized_option(\n    \"--lr\",\n    default=args.lr,\n    type=float,\n    help=\"Maximum learning rate\",\n    category=\"Optimizer\",\n)\n@categorized_option(\n    \"--weight_ncc\",\n    default=args.weight_ncc,\n    type=float,\n    help=\"Weight on mNCC loss term\",\n    category=\"Optimizer\",\n)\n@categorized_option(\n    \"--weight_geo\",\n    default=args.weight_geo,\n    type=float,\n    help=\"Weight on geodesic loss term\",\n    category=\"Optimizer\",\n)\n@categorized_option(\n    \"--weight_dice\",\n    default=args.weight_dice,\n    type=float,\n    help=\"Weight on Dice loss term\",\n    category=\"Optimizer\",\n)\n@categorized_option(\n    \"--weight_mvc\",\n    default=args.weight_mvc,\n    type=float,\n    help=\"Weight on multiview consistency loss term\",\n    category=\"Optimizer\",\n)\n@categorized_option(\n    \"--batch_size\",\n    default=args.batch_size,\n    type=int,\n    help=\"Number of DRRs per batch\",\n    category=\"Sampling\",\n)\n@categorized_option(\n    \"--n_total_itrs\",\n    default=args.n_total_itrs,\n    type=int,\n    help=\"Number of iterations for training the model\",\n    category=\"Optimizer\",\n)\n@categorized_option(\n    \"--n_warmup_itrs\",\n    default=args.n_warmup_itrs,\n    type=int,\n    help=\"Number of iterations for warming up the learning rate\",\n    category=\"Optimizer\",\n)\n@categorized_option(\n    \"--n_grad_accum_itrs\",\n    default=args.n_grad_accum_itrs,\n    type=int,\n    help=\"Number of iterations for gradient accumulation\",\n    category=\"Optimizer\",\n)\n@categorized_option(\n    \"--n_save_every_itrs\",\n    default=args.n_save_every_itrs,\n    type=int,\n    help=\"Number of iterations before saving a new model checkpoint\",\n    category=\"Optimizer\",\n)\n@categorized_option(\n    \"--disable_scheduler\",\n    default=args.disable_scheduler,\n    is_flag=True,\n    help=\"Turn off cosine learning rate scheduler\",\n    category=\"Optimizer\",\n)\n@categorized_option(\n    \"--reuse_optimizer\",\n    default=args.reuse_optimizer,\n    is_flag=True,\n    help=\"If ckptpath passed, initialize the previous optimizer's state\",\n    category=\"Checkpoint\",\n)\n@categorized_option(\n    \"-w\",\n    \"--warp\",\n    type=click.Path(exists=True),\n    help=\"SimpleITK transform to warp input CT to the checkpoint's reference frame\",\n    category=\"Checkpoint\",\n)\n@categorized_option(\n    \"--invert\",\n    default=args.invert,\n    is_flag=True,\n    help=\"Whether to invert the warp or not\",\n    category=\"Checkpoint\",\n)\n@categorized_option(\n    \"--patch_size\",\n    default=None,\n    type=str,\n    help=\"Optional random crop size (e.g., 'h,w,d'); if None, return entire volume\",\n    category=\"Data\",\n)\n@categorized_option(\n    \"--num_workers\",\n    default=args.num_workers,\n    type=int,\n    help=\"Number of subprocesses to use in the dataloader\",\n    category=\"Data\",\n)\n@categorized_option(\n    \"--pin_memory\",\n    default=args.pin_memory,\n    is_flag=True,\n    help=\"Copy volumes from the dataloader into CUDA pinned memory before returning\",\n    category=\"Data\",\n)\n@categorized_option(\n    \"--sample_weights\",\n    default=None,\n    type=click.Path(exists=True),\n    help=\"Probability for sampling each volume in `volpath`\",\n    category=\"Data\",\n)\n@categorized_option(\n    \"--name\",\n    default=None,\n    type=str,\n    help=\"WandB run name\",\n    category=\"Logging\",\n)\n@categorized_option(\n    \"--id\",\n    default=None,\n    type=str,\n    help=\"WandB run ID (useful when restarting from a checkpoint)\",\n    category=\"Logging\",\n)\n@categorized_option(\n    \"--project\",\n    default=args.project,\n    type=str,\n    help=\"WandB project name\",\n    category=\"Logging\",\n)\ndef train(\n    volpath,\n    maskpath,\n    ckptpath,\n    outpath,\n    r1,\n    r2,\n    r3,\n    tx,\n    ty,\n    tz,\n    sdd,\n    height,\n    delx,\n    renderer,\n    orientation,\n    reverse_x_axis,\n    model_name,\n    norm_layer,\n    pretrained,\n    parameterization,\n    convention,\n    unit_conversion_factor,\n    p_augmentation,\n    lr,\n    weight_ncc,\n    weight_geo,\n    weight_dice,\n    weight_mvc,\n    batch_size,\n    n_total_itrs,\n    n_warmup_itrs,\n    n_grad_accum_itrs,\n    n_save_every_itrs,\n    disable_scheduler,\n    reuse_optimizer,\n    warp,\n    invert,\n    patch_size,\n    num_workers,\n    pin_memory,\n    sample_weights,\n    name,\n    id,\n    project,\n):\n    \"\"\"Train a pose regression model.\"\"\"\n    import os\n    from pathlib import Path\n\n    import wandb\n\n    from ...model import Trainer\n\n    # Create the output directory for saving model weights\n    Path(outpath).mkdir(parents=True, exist_ok=True)\n\n    # If ckptpath is a directory, get the last saved model\n    if ckptpath is not None:\n        ckptpath = Path(ckptpath)\n        if ckptpath.is_dir():\n            ckptpath = max(ckptpath.glob(\"*.pth\"), key=lambda p: p.name)\n        ckptpath = str(ckptpath)\n\n    # Parse patch_size\n    if patch_size is not None:\n        patch_size = tuple(int(x) for x in patch_size.split(\",\"))\n\n    # Parse 6-DoF pose parameters\n    alphamin, alphamax = r1\n    betamin, betamax = r2\n    gammamin, gammamax = r3\n    txmin, txmax = tx\n    tymin, tymax = ty\n    tzmin, tzmax = tz\n\n    # Parse the sample weights\n    weights = (\n        [float(line) for line in Path(sample_weights).read_text().splitlines()]\n        if sample_weights is not None\n        else None\n    )\n\n    # Parse configuration parameters\n    config = dict(\n        volpath=volpath,\n        maskpath=maskpath,\n        ckptpath=ckptpath,\n        outpath=outpath,\n        alphamin=alphamin,\n        alphamax=alphamax,\n        betamin=betamin,\n        betamax=betamax,\n        gammamin=gammamin,\n        gammamax=gammamax,\n        txmin=txmin,\n        txmax=txmax,\n        tymin=tymin,\n        tymax=tymax,\n        tzmin=tzmin,\n        tzmax=tzmax,\n        sdd=sdd,\n        height=height,\n        delx=delx,\n        renderer=renderer,\n        orientation=orientation,\n        reverse_x_axis=reverse_x_axis,\n        parameterization=parameterization,\n        convention=convention,\n        model_name=model_name,\n        pretrained=pretrained,\n        norm_layer=norm_layer,\n        unit_conversion_factor=unit_conversion_factor,\n        p_augmentation=p_augmentation,\n        lr=lr,\n        weight_ncc=weight_ncc,\n        weight_geo=weight_geo,\n        weight_dice=weight_dice,\n        weight_mvc=weight_mvc,\n        batch_size=batch_size,\n        n_total_itrs=n_total_itrs,\n        n_warmup_itrs=n_warmup_itrs,\n        n_grad_accum_itrs=n_grad_accum_itrs,\n        n_save_every_itrs=n_save_every_itrs,\n        disable_scheduler=disable_scheduler,\n        reuse_optimizer=reuse_optimizer,\n        patch_size=patch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        weights=weights,\n        warp=warp,\n        invert=invert,\n    )\n\n    # Set up logging\n    wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n    run = wandb.init(\n        project=project,\n        name=name if name is not None else project,\n        config=config,\n        id=id,\n        resume=\"must\" if id is not None else None,\n    )\n\n    # Train the model\n    trainer = Trainer(**config)\n    trainer.train(run)\n</code></pre>"},{"location":"reference/xvr/config/","title":"config","text":""},{"location":"reference/xvr/config/#xvr.config","title":"xvr.config","text":""},{"location":"reference/xvr/config/#xvr.config.RegistrarArgs","title":"RegistrarArgs  <code>dataclass</code>","text":"<pre><code>RegistrarArgs(\n    crop: int = 0,\n    subtract_background: bool = False,\n    linearize: bool = False,\n    equalize: bool = False,\n    reducefn: str = \"max\",\n    pattern: str = \"*.dcm\",\n    reverse_x_axis: bool = False,\n    renderer: str = \"trilinear\",\n    voxel_shift: float = 0.0,\n    scales: str = \"8\",\n    n_itrs: str = \"500\",\n    parameterization: str = \"euler_angles\",\n    convention: str = \"ZXY\",\n    lr_rot: float = 0.01,\n    lr_xyz: float = 1.0,\n    patience: int = 10,\n    threshold: float = 0.0001,\n    max_n_plateaus: int = 3,\n    init_only: bool = False,\n    saveimg: bool = False,\n    verbose: int = 1,\n)\n</code></pre> <p>Default arguments for registration.</p>"},{"location":"reference/xvr/config/#xvr.config.TrainerArgs","title":"TrainerArgs  <code>dataclass</code>","text":"<pre><code>TrainerArgs(\n    renderer: str = \"trilinear\",\n    orientation: str = \"AP\",\n    reverse_x_axis: bool = False,\n    model_name: str = \"resnet18\",\n    norm_layer: str = \"groupnorm\",\n    pretrained: bool = False,\n    parameterization: str = \"quaternion_adjugate\",\n    convention: str = \"ZXY\",\n    unit_conversion_factor: float = 1000.0,\n    p_augmentation: float = 0.333,\n    lr: float = 0.0002,\n    weight_ncc: float = 1.0,\n    weight_geo: float = 0.01,\n    weight_dice: float = 1.0,\n    weight_mvc: float = 0,\n    batch_size: int = 116,\n    n_total_itrs: int = 1000000,\n    n_warmup_itrs: int = 1000,\n    n_grad_accum_itrs: int = 4,\n    n_save_every_itrs: int = 1000,\n    disable_scheduler: bool = False,\n    reuse_optimizer: bool = False,\n    invert: bool = False,\n    num_workers: int = 4,\n    pin_memory: bool = False,\n    project: str = \"xvr\",\n)\n</code></pre> <p>Default arguments for training.</p>"},{"location":"reference/xvr/config/registrar/","title":"registrar","text":""},{"location":"reference/xvr/config/registrar/#xvr.config.registrar","title":"xvr.config.registrar","text":""},{"location":"reference/xvr/config/registrar/#xvr.config.registrar.RegistrarArgs","title":"RegistrarArgs  <code>dataclass</code>","text":"<pre><code>RegistrarArgs(\n    crop: int = 0,\n    subtract_background: bool = False,\n    linearize: bool = False,\n    equalize: bool = False,\n    reducefn: str = \"max\",\n    pattern: str = \"*.dcm\",\n    reverse_x_axis: bool = False,\n    renderer: str = \"trilinear\",\n    voxel_shift: float = 0.0,\n    scales: str = \"8\",\n    n_itrs: str = \"500\",\n    parameterization: str = \"euler_angles\",\n    convention: str = \"ZXY\",\n    lr_rot: float = 0.01,\n    lr_xyz: float = 1.0,\n    patience: int = 10,\n    threshold: float = 0.0001,\n    max_n_plateaus: int = 3,\n    init_only: bool = False,\n    saveimg: bool = False,\n    verbose: int = 1,\n)\n</code></pre> <p>Default arguments for registration.</p>"},{"location":"reference/xvr/config/trainer/","title":"trainer","text":""},{"location":"reference/xvr/config/trainer/#xvr.config.trainer","title":"xvr.config.trainer","text":""},{"location":"reference/xvr/config/trainer/#xvr.config.trainer.TrainerArgs","title":"TrainerArgs  <code>dataclass</code>","text":"<pre><code>TrainerArgs(\n    renderer: str = \"trilinear\",\n    orientation: str = \"AP\",\n    reverse_x_axis: bool = False,\n    model_name: str = \"resnet18\",\n    norm_layer: str = \"groupnorm\",\n    pretrained: bool = False,\n    parameterization: str = \"quaternion_adjugate\",\n    convention: str = \"ZXY\",\n    unit_conversion_factor: float = 1000.0,\n    p_augmentation: float = 0.333,\n    lr: float = 0.0002,\n    weight_ncc: float = 1.0,\n    weight_geo: float = 0.01,\n    weight_dice: float = 1.0,\n    weight_mvc: float = 0,\n    batch_size: int = 116,\n    n_total_itrs: int = 1000000,\n    n_warmup_itrs: int = 1000,\n    n_grad_accum_itrs: int = 4,\n    n_save_every_itrs: int = 1000,\n    disable_scheduler: bool = False,\n    reuse_optimizer: bool = False,\n    invert: bool = False,\n    num_workers: int = 4,\n    pin_memory: bool = False,\n    project: str = \"xvr\",\n)\n</code></pre> <p>Default arguments for training.</p>"},{"location":"reference/xvr/io/","title":"io","text":""},{"location":"reference/xvr/io/#xvr.io","title":"xvr.io","text":""},{"location":"reference/xvr/io/#xvr.io.read_xray","title":"read_xray","text":"<pre><code>read_xray(\n    filename: Path,\n    crop: int = 0,\n    subtract_background: bool = False,\n    linearize: bool = True,\n    reducefn: str | int | Callable = \"max\",\n)\n</code></pre> <p>Read and preprocess an X-ray image from a DICOM file. Returns the pixel array and imaging system intrinsics.</p> Path <p>Path to the DICOM file.</p> <p>crop : int, optional     Number of pixels to crop from each edge of the image. subtract_background : bool, optional     Subtract the mode image intensity from the image. linearize : bool, optional     Convert the X-ray image from exponential to linear form. reducefn :     If DICOM is multiframe, how to extract a single 2D image for registration.</p> Source code in <code>src/xvr/io/xray.py</code> <pre><code>def read_xray(\n    filename: Path,\n    crop: int = 0,\n    subtract_background: bool = False,\n    linearize: bool = True,\n    reducefn: str | int | Callable = \"max\",\n):\n    \"\"\"\n    Read and preprocess an X-ray image from a DICOM file. Returns the pixel array and imaging system intrinsics.\n\n    filename : Path\n        Path to the DICOM file.\n    crop : int, optional\n        Number of pixels to crop from each edge of the image.\n    subtract_background : bool, optional\n        Subtract the mode image intensity from the image.\n    linearize : bool, optional\n        Convert the X-ray image from exponential to linear form.\n    reducefn :\n        If DICOM is multiframe, how to extract a single 2D image for registration.\n    \"\"\"\n\n    # Get the image and imaging system intrinsics\n    img, sdd, delx, dely, x0, y0, pf_to_af = _parse_dicom(filename)\n\n    # Preprocess the X-ray image\n    img = _preprocess_xray(img, crop, subtract_background, linearize, reducefn)\n\n    return img, sdd, delx, dely, x0, y0, pf_to_af\n</code></pre>"},{"location":"reference/xvr/io/xray/","title":"xray","text":""},{"location":"reference/xvr/io/xray/#xvr.io.xray","title":"xvr.io.xray","text":""},{"location":"reference/xvr/io/xray/#xvr.io.xray.read_xray","title":"read_xray","text":"<pre><code>read_xray(\n    filename: Path,\n    crop: int = 0,\n    subtract_background: bool = False,\n    linearize: bool = True,\n    reducefn: str | int | Callable = \"max\",\n)\n</code></pre> <p>Read and preprocess an X-ray image from a DICOM file. Returns the pixel array and imaging system intrinsics.</p> Path <p>Path to the DICOM file.</p> <p>crop : int, optional     Number of pixels to crop from each edge of the image. subtract_background : bool, optional     Subtract the mode image intensity from the image. linearize : bool, optional     Convert the X-ray image from exponential to linear form. reducefn :     If DICOM is multiframe, how to extract a single 2D image for registration.</p> Source code in <code>src/xvr/io/xray.py</code> <pre><code>def read_xray(\n    filename: Path,\n    crop: int = 0,\n    subtract_background: bool = False,\n    linearize: bool = True,\n    reducefn: str | int | Callable = \"max\",\n):\n    \"\"\"\n    Read and preprocess an X-ray image from a DICOM file. Returns the pixel array and imaging system intrinsics.\n\n    filename : Path\n        Path to the DICOM file.\n    crop : int, optional\n        Number of pixels to crop from each edge of the image.\n    subtract_background : bool, optional\n        Subtract the mode image intensity from the image.\n    linearize : bool, optional\n        Convert the X-ray image from exponential to linear form.\n    reducefn :\n        If DICOM is multiframe, how to extract a single 2D image for registration.\n    \"\"\"\n\n    # Get the image and imaging system intrinsics\n    img, sdd, delx, dely, x0, y0, pf_to_af = _parse_dicom(filename)\n\n    # Preprocess the X-ray image\n    img = _preprocess_xray(img, crop, subtract_background, linearize, reducefn)\n\n    return img, sdd, delx, dely, x0, y0, pf_to_af\n</code></pre>"},{"location":"reference/xvr/metrics/","title":"metrics","text":""},{"location":"reference/xvr/metrics/#xvr.metrics","title":"xvr.metrics","text":""},{"location":"reference/xvr/metrics/#xvr.metrics.Evaluator","title":"Evaluator","text":"<pre><code>Evaluator(drr: DRR, fiducials: Tensor)\n</code></pre> <p>Calculate four 2D/3D registration error metrics (all in mm).</p> Source code in <code>src/xvr/metrics/evaluator.py</code> <pre><code>def __init__(self, drr: DRR, fiducials: torch.Tensor):\n    self.drr = drr\n    self.fiducials = fiducials\n    self.geodesic = DoubleGeodesicSE3(drr.detector.sdd, eps=0.0)\n</code></pre>"},{"location":"reference/xvr/metrics/evaluator/","title":"evaluator","text":""},{"location":"reference/xvr/metrics/evaluator/#xvr.metrics.evaluator","title":"xvr.metrics.evaluator","text":""},{"location":"reference/xvr/metrics/evaluator/#xvr.metrics.evaluator.Evaluator","title":"Evaluator","text":"<pre><code>Evaluator(drr: DRR, fiducials: Tensor)\n</code></pre> <p>Calculate four 2D/3D registration error metrics (all in mm).</p> Source code in <code>src/xvr/metrics/evaluator.py</code> <pre><code>def __init__(self, drr: DRR, fiducials: torch.Tensor):\n    self.drr = drr\n    self.fiducials = fiducials\n    self.geodesic = DoubleGeodesicSE3(drr.detector.sdd, eps=0.0)\n</code></pre>"},{"location":"reference/xvr/model/","title":"model","text":""},{"location":"reference/xvr/model/#xvr.model","title":"xvr.model","text":""},{"location":"reference/xvr/model/#xvr.model.get_random_pose","title":"get_random_pose","text":"<pre><code>get_random_pose(\n    alphamin,\n    alphamax,\n    betamin,\n    betamax,\n    gammamin,\n    gammamax,\n    txmin,\n    txmax,\n    tymin,\n    tymax,\n    tzmin,\n    tzmax,\n    batch_size,\n)\n</code></pre> <p>Generate a batch of random poses in SE(3) using specified ranges.</p> Source code in <code>src/xvr/model/sampler.py</code> <pre><code>def get_random_pose(\n    alphamin,\n    alphamax,\n    betamin,\n    betamax,\n    gammamin,\n    gammamax,\n    txmin,\n    txmax,\n    tymin,\n    tymax,\n    tzmin,\n    tzmax,\n    batch_size,\n):\n    \"\"\"Generate a batch of random poses in SE(3) using specified ranges.\"\"\"\n    alpha = uniform(alphamin, alphamax, batch_size, circle_shift=True)\n    beta = uniform(betamin, betamax, batch_size, circle_shift=True)\n    gamma = uniform(gammamin, gammamax, batch_size, circle_shift=True)\n    tx = uniform(txmin, txmax, batch_size)\n    ty = uniform(tymin, tymax, batch_size)\n    tz = uniform(tzmin, tzmax, batch_size)\n    rot = torch.concat([alpha, beta, gamma], dim=1)\n    xyz = torch.concat([tx, ty, tz], dim=1)\n    return convert(\n        rot, xyz, parameterization=\"euler_angles\", convention=\"ZXY\", degrees=True\n    )\n</code></pre>"},{"location":"reference/xvr/model/augmentations/","title":"augmentations","text":""},{"location":"reference/xvr/model/augmentations/#xvr.model.augmentations","title":"xvr.model.augmentations","text":""},{"location":"reference/xvr/model/augmentations/#xvr.model.augmentations.RandomCenterCrop","title":"RandomCenterCrop","text":"<pre><code>RandomCenterCrop(maxcrop: int, p: float = 0.5)\n</code></pre> <p>Simulate collimation.</p> Source code in <code>src/xvr/model/augmentations.py</code> <pre><code>def __init__(self, maxcrop: int, p: float = 0.5):\n    super().__init__(p=p)\n    self.maxcrop = maxcrop\n</code></pre>"},{"location":"reference/xvr/model/inference/","title":"inference","text":""},{"location":"reference/xvr/model/inference/#xvr.model.inference","title":"xvr.model.inference","text":""},{"location":"reference/xvr/model/loss/","title":"loss","text":""},{"location":"reference/xvr/model/loss/#xvr.model.loss","title":"xvr.model.loss","text":""},{"location":"reference/xvr/model/loss/#xvr.model.loss.DiceMetric","title":"DiceMetric","text":"<pre><code>DiceMetric()\n</code></pre> Source code in <code>src/xvr/model/loss.py</code> <pre><code>def __init__(self):\n    super().__init__()\n</code></pre>"},{"location":"reference/xvr/model/loss/#xvr.model.loss.DiceMetric.forward","title":"forward","text":"<pre><code>forward(y_pred, y_true)\n</code></pre> <p>Compute 2D Dice coefficient between to multi-channel labelmaps. Assumes the first channel in each image is background.</p> <p>Equivalent to monai.metrics.DiceMetric(include_background=False, reduction=\"none\")</p> Source code in <code>src/xvr/model/loss.py</code> <pre><code>def forward(self, y_pred, y_true):\n    \"\"\"\n    Compute 2D Dice coefficient between to multi-channel labelmaps.\n    Assumes the first channel in each image is background.\n\n    Equivalent to monai.metrics.DiceMetric(include_background=False, reduction=\"none\")\n    \"\"\"\n\n    # Flatten spatial dimensions\n    y_pred = y_pred.view(y_pred.shape[0], y_pred.shape[1], -1)  # (B, C, H*W)\n    y_true = y_true.view(y_true.shape[0], y_true.shape[1], -1)  # (B, C, H*W)\n\n    # Compute intersection and union\n    intersection = (y_pred * y_true).sum(dim=2)  # (B, C)\n    pred_sum = y_pred.sum(dim=2)  # (B, C)\n    true_sum = y_true.sum(dim=2)  # (B, C)\n\n    # Compute Dice coefficient\n    dice = (2.0 * intersection) / (pred_sum + true_sum)\n\n    # Exclude background (assume background is channel 0)\n    dice = dice[:, 1:]\n\n    return dice\n</code></pre>"},{"location":"reference/xvr/model/network/","title":"network","text":""},{"location":"reference/xvr/model/network/#xvr.model.network","title":"xvr.model.network","text":""},{"location":"reference/xvr/model/network/#xvr.model.network.PoseRegressor","title":"PoseRegressor","text":"<pre><code>PoseRegressor(\n    model_name,\n    parameterization,\n    convention=None,\n    pretrained=False,\n    height=256,\n    unit_conversion_factor=1000.0,\n    **kwargs\n)\n</code></pre> <p>A PoseRegressor is comprised of a pretrained backbone model that extracts features from an input X-ray and two linear layers that decode these features into rotational and translational camera pose parameters, respectively.</p> Source code in <code>src/xvr/model/network.py</code> <pre><code>def __init__(\n    self,\n    model_name,\n    parameterization,\n    convention=None,\n    pretrained=False,\n    height=256,\n    unit_conversion_factor=1000.0,\n    **kwargs,\n):\n    super().__init__()\n\n    self.parameterization = parameterization\n    self.convention = convention\n    n_angular_components = N_ANGULAR_COMPONENTS[parameterization]\n\n    # Get the size of the output from the backbone\n    self.backbone = timm.create_model(\n        model_name,\n        pretrained,\n        num_classes=0,\n        in_chans=1,\n        **kwargs,\n    )\n    output = self.backbone(torch.randn(1, 1, height, height)).shape[-1]\n    self.xyz_regression = torch.nn.Linear(output, 3)\n    self.rot_regression = torch.nn.Linear(output, n_angular_components)\n\n    # E.g., if 1000.0, converts output from meters to millimeters\n    self.unit_conversion_factor = unit_conversion_factor\n</code></pre>"},{"location":"reference/xvr/model/network/#xvr.model.network.load_model","title":"load_model","text":"<pre><code>load_model(ckptpath, meta=False)\n</code></pre> <p>Load a pretrained pose regression model</p> Source code in <code>src/xvr/model/network.py</code> <pre><code>def load_model(ckptpath, meta=False):\n    \"\"\"Load a pretrained pose regression model\"\"\"\n    ckpt = torch.load(ckptpath, weights_only=False)\n    config = ckpt[\"config\"]\n\n    model_state_dict = ckpt[\"model_state_dict\"]\n    model = PoseRegressor(\n        model_name=config[\"model_name\"],\n        parameterization=config[\"parameterization\"],\n        convention=config[\"convention\"],\n        norm_layer=config[\"norm_layer\"],\n        height=config[\"height\"],\n        unit_conversion_factor=config.get(\"unit_conversion_factor\", 1.0),\n    ).cuda()\n    model.load_state_dict(model_state_dict)\n    model.eval()\n\n    if meta:\n        return model, config, ckpt[\"date\"]\n    else:\n        return model, config\n</code></pre>"},{"location":"reference/xvr/model/sampler/","title":"sampler","text":""},{"location":"reference/xvr/model/sampler/#xvr.model.sampler","title":"xvr.model.sampler","text":""},{"location":"reference/xvr/model/sampler/#xvr.model.sampler.get_random_pose","title":"get_random_pose","text":"<pre><code>get_random_pose(\n    alphamin,\n    alphamax,\n    betamin,\n    betamax,\n    gammamin,\n    gammamax,\n    txmin,\n    txmax,\n    tymin,\n    tymax,\n    tzmin,\n    tzmax,\n    batch_size,\n)\n</code></pre> <p>Generate a batch of random poses in SE(3) using specified ranges.</p> Source code in <code>src/xvr/model/sampler.py</code> <pre><code>def get_random_pose(\n    alphamin,\n    alphamax,\n    betamin,\n    betamax,\n    gammamin,\n    gammamax,\n    txmin,\n    txmax,\n    tymin,\n    tymax,\n    tzmin,\n    tzmax,\n    batch_size,\n):\n    \"\"\"Generate a batch of random poses in SE(3) using specified ranges.\"\"\"\n    alpha = uniform(alphamin, alphamax, batch_size, circle_shift=True)\n    beta = uniform(betamin, betamax, batch_size, circle_shift=True)\n    gamma = uniform(gammamin, gammamax, batch_size, circle_shift=True)\n    tx = uniform(txmin, txmax, batch_size)\n    ty = uniform(tymin, tymax, batch_size)\n    tz = uniform(tzmin, tzmax, batch_size)\n    rot = torch.concat([alpha, beta, gamma], dim=1)\n    xyz = torch.concat([tx, ty, tz], dim=1)\n    return convert(\n        rot, xyz, parameterization=\"euler_angles\", convention=\"ZXY\", degrees=True\n    )\n</code></pre>"},{"location":"reference/xvr/model/scheduler/","title":"scheduler","text":""},{"location":"reference/xvr/model/scheduler/#xvr.model.scheduler","title":"xvr.model.scheduler","text":""},{"location":"reference/xvr/model/scheduler/#xvr.model.scheduler.WarmupCosineSchedule","title":"WarmupCosineSchedule","text":"<pre><code>WarmupCosineSchedule(\n    optimizer, warmup_steps, t_total, cycles=0.5, last_epoch=-1\n)\n</code></pre> <p>Linear warmup and then cosine decay. Linearly increases learning rate from 0 to 1 over <code>warmup_steps</code> training steps. Decreases learning rate from 1. to 0. over remaining <code>t_total - warmup_steps</code> steps following a cosine curve. If <code>cycles</code> (default=0.5) is different from default, learning rate follows cosine function after warmup.</p> <p>Copied from https://github.com/TalSchuster/pytorch-transformers/blob/64fff2a53977ac1caac32c960d2b01f16b7eb913/pytorch_transformers/optimization.py#L64-L81</p> Source code in <code>src/xvr/model/scheduler.py</code> <pre><code>def __init__(self, optimizer, warmup_steps, t_total, cycles=0.5, last_epoch=-1):\n    self.warmup_steps = warmup_steps\n    self.t_total = t_total\n    self.cycles = cycles\n    super().__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n</code></pre>"},{"location":"reference/xvr/model/trainer/","title":"trainer","text":""},{"location":"reference/xvr/model/trainer/#xvr.model.trainer","title":"xvr.model.trainer","text":""},{"location":"reference/xvr/model/utils/","title":"utils","text":""},{"location":"reference/xvr/model/utils/#xvr.model.utils","title":"xvr.model.utils","text":""},{"location":"reference/xvr/registrar/","title":"registrar","text":""},{"location":"reference/xvr/registrar/#xvr.registrar","title":"xvr.registrar","text":""},{"location":"reference/xvr/registrar/base/","title":"base","text":""},{"location":"reference/xvr/registrar/base/#xvr.registrar.base","title":"xvr.registrar.base","text":""},{"location":"reference/xvr/registrar/dicom/","title":"dicom","text":""},{"location":"reference/xvr/registrar/dicom/#xvr.registrar.dicom","title":"xvr.registrar.dicom","text":""},{"location":"reference/xvr/registrar/fixed/","title":"fixed","text":""},{"location":"reference/xvr/registrar/fixed/#xvr.registrar.fixed","title":"xvr.registrar.fixed","text":""},{"location":"reference/xvr/registrar/model/","title":"model","text":""},{"location":"reference/xvr/registrar/model/#xvr.registrar.model","title":"xvr.registrar.model","text":""},{"location":"reference/xvr/registrar/restart/","title":"restart","text":""},{"location":"reference/xvr/registrar/restart/#xvr.registrar.restart","title":"xvr.registrar.restart","text":""},{"location":"reference/xvr/renderer/","title":"renderer","text":""},{"location":"reference/xvr/renderer/#xvr.renderer","title":"xvr.renderer","text":""},{"location":"reference/xvr/renderer/load/","title":"load","text":""},{"location":"reference/xvr/renderer/load/#xvr.renderer.load","title":"xvr.renderer.load","text":""},{"location":"reference/xvr/utils/","title":"utils","text":""},{"location":"reference/xvr/utils/#xvr.utils","title":"xvr.utils","text":""},{"location":"reference/xvr/utils/#xvr.utils.ants_rigid_register","title":"ants_rigid_register","text":"<pre><code>ants_rigid_register(fix_filename, mov_filename, savepath)\n</code></pre> <p>Rigidly register the new volume to the template with ANTs.</p> Source code in <code>src/xvr/utils/ants.py</code> <pre><code>def ants_rigid_register(fix_filename, mov_filename, savepath):\n    \"\"\"Rigidly register the new volume to the template with ANTs.\"\"\"\n    img_fix = ants.image_read(fix_filename)\n    img_mov = ants.image_read(mov_filename)\n    result = ants.registration(\n        img_fix,\n        img_mov,\n        type_of_transform=\"Rigid\",\n        aff_random_sampling_rate=0.666,\n        aff_iterations=(200, 200, 50),\n        aff_shrink_factors=(6, 4, 2),\n        aff_smoothing_sigmas=(3, 2, 1),\n    )\n    transform = ants.read_transform(result[\"fwdtransforms\"][0])\n    ants.write_transform(transform, savepath)\n</code></pre>"},{"location":"reference/xvr/utils/#xvr.utils.get_4x4","title":"get_4x4","text":"<pre><code>get_4x4(mat, img, invert=False)\n</code></pre> <p>Get the rigid or affine matrix for warping img_warped -&gt; img.</p> Source code in <code>src/xvr/utils/ants.py</code> <pre><code>def get_4x4(mat, img, invert=False):\n    \"\"\"Get the rigid or affine matrix for warping img_warped -&gt; img.\"\"\"\n    img = torchio.ScalarImage(img)\n\n    transform = ants.read_transform(mat)\n    if invert:\n        transform = transform.invert()\n    R = transform.parameters[:9].reshape(3, 3)\n    t = transform.parameters[9:]\n    c = transform.fixed_parameters\n    global_t = -R @ c + t + c\n\n    M = np.eye(4)\n    M[:3, :3] = R\n    M[:3, 3] = global_t\n\n    D = np.eye(4)\n    if img.orientation == (\"L\", \"P\", \"S\"):\n        D[:3, :3] = np.array(img.direction).reshape(3, 3)\n    elif img.orientation == (\"R\", \"A\", \"S\"):\n        D[:3, :3] = direction(img)\n    else:\n        warnings.warn(\n            f\"Unrecognized orientation {img.orientation}; assuming LPS+ directions. If the corrected pose is completely wrong, check here first.\"\n        )\n        D[:3, :3] = np.array(img.direction).reshape(3, 3)\n\n    Tinv = np.eye(4)\n    Tinv[:3, 3] = -np.array(img.get_center())\n\n    T = Tinv @ D @ M @ np.linalg.inv(D)\n    T = torch.from_numpy(T).to(torch.float32)\n    T = RigidTransform(T)\n\n    return project_onto_SO3(T)\n</code></pre>"},{"location":"reference/xvr/utils/ants/","title":"ants","text":""},{"location":"reference/xvr/utils/ants/#xvr.utils.ants","title":"xvr.utils.ants","text":""},{"location":"reference/xvr/utils/ants/#xvr.utils.ants.get_4x4","title":"get_4x4","text":"<pre><code>get_4x4(mat, img, invert=False)\n</code></pre> <p>Get the rigid or affine matrix for warping img_warped -&gt; img.</p> Source code in <code>src/xvr/utils/ants.py</code> <pre><code>def get_4x4(mat, img, invert=False):\n    \"\"\"Get the rigid or affine matrix for warping img_warped -&gt; img.\"\"\"\n    img = torchio.ScalarImage(img)\n\n    transform = ants.read_transform(mat)\n    if invert:\n        transform = transform.invert()\n    R = transform.parameters[:9].reshape(3, 3)\n    t = transform.parameters[9:]\n    c = transform.fixed_parameters\n    global_t = -R @ c + t + c\n\n    M = np.eye(4)\n    M[:3, :3] = R\n    M[:3, 3] = global_t\n\n    D = np.eye(4)\n    if img.orientation == (\"L\", \"P\", \"S\"):\n        D[:3, :3] = np.array(img.direction).reshape(3, 3)\n    elif img.orientation == (\"R\", \"A\", \"S\"):\n        D[:3, :3] = direction(img)\n    else:\n        warnings.warn(\n            f\"Unrecognized orientation {img.orientation}; assuming LPS+ directions. If the corrected pose is completely wrong, check here first.\"\n        )\n        D[:3, :3] = np.array(img.direction).reshape(3, 3)\n\n    Tinv = np.eye(4)\n    Tinv[:3, 3] = -np.array(img.get_center())\n\n    T = Tinv @ D @ M @ np.linalg.inv(D)\n    T = torch.from_numpy(T).to(torch.float32)\n    T = RigidTransform(T)\n\n    return project_onto_SO3(T)\n</code></pre>"},{"location":"reference/xvr/utils/ants/#xvr.utils.ants.ants_rigid_register","title":"ants_rigid_register","text":"<pre><code>ants_rigid_register(fix_filename, mov_filename, savepath)\n</code></pre> <p>Rigidly register the new volume to the template with ANTs.</p> Source code in <code>src/xvr/utils/ants.py</code> <pre><code>def ants_rigid_register(fix_filename, mov_filename, savepath):\n    \"\"\"Rigidly register the new volume to the template with ANTs.\"\"\"\n    img_fix = ants.image_read(fix_filename)\n    img_mov = ants.image_read(mov_filename)\n    result = ants.registration(\n        img_fix,\n        img_mov,\n        type_of_transform=\"Rigid\",\n        aff_random_sampling_rate=0.666,\n        aff_iterations=(200, 200, 50),\n        aff_shrink_factors=(6, 4, 2),\n        aff_smoothing_sigmas=(3, 2, 1),\n    )\n    transform = ants.read_transform(result[\"fwdtransforms\"][0])\n    ants.write_transform(transform, savepath)\n</code></pre>"},{"location":"reference/xvr/utils/ants/#xvr.utils.ants.direction","title":"direction","text":"<pre><code>direction(img: ScalarImage)\n</code></pre> <p>Volume directions in RAS space (comport with ANTS convention).</p> Source code in <code>src/xvr/utils/ants.py</code> <pre><code>def direction(img: torchio.ScalarImage):\n    \"\"\"Volume directions in RAS space (comport with ANTS convention).\"\"\"\n    *_, direction = get_sitk_metadata_from_ras_affine(img.affine)\n    return np.array(direction).reshape(3, 3)\n</code></pre>"},{"location":"reference/xvr/utils/ants/#xvr.utils.ants.project_onto_SO3","title":"project_onto_SO3","text":"<pre><code>project_onto_SO3(T: RigidTransform)\n</code></pre> <p>Convert the upper 3x3 to a matrix in SO(3) (i.e., unitary with det=+1).</p> Source code in <code>src/xvr/utils/ants.py</code> <pre><code>def project_onto_SO3(T: RigidTransform):\n    \"\"\"Convert the upper 3x3 to a matrix in SO(3) (i.e., unitary with det=+1).\"\"\"\n    M = T.matrix[0]\n    A = M[:3, :3]\n    At = M[:3, 3]\n    U, S, V = A.svd()\n    t = A.inverse() @ At\n    S = torch.ones_like(S)\n    S[..., -1] = (U @ V.mT).det()\n    R = torch.einsum(\"ij, j, jk -&gt; ik\", U, S, V.mT)\n    t = R @ t\n    return RigidTransform(make_matrix(R[None], t[None]))\n</code></pre>"},{"location":"reference/xvr/utils/preprocess/","title":"preprocess","text":""},{"location":"reference/xvr/utils/preprocess/#xvr.utils.preprocess","title":"xvr.utils.preprocess","text":""},{"location":"reference/xvr/visualization/","title":"visualization","text":""},{"location":"reference/xvr/visualization/#xvr.visualization","title":"xvr.visualization","text":""},{"location":"reference/xvr/visualization/animate/","title":"animate","text":""},{"location":"reference/xvr/visualization/animate/#xvr.visualization.animate","title":"xvr.visualization.animate","text":""},{"location":"reference/xvr/visualization/animate/#xvr.visualization.animate.animate","title":"animate","text":"<pre><code>animate(\n    inpath: str | Path,\n    outpath: str | Path,\n    skip: int = 1,\n    dpi: int = 192,\n    fps: int = 30,\n)\n</code></pre> <p>Animate the trajectory of iterative optimization.</p> Source code in <code>src/xvr/visualization/animate.py</code> <pre><code>def animate(\n    inpath: str | Path,  # Saved registration result from &lt;xvr register&gt;\n    outpath: str | Path,  # Savepath for iterative optimization animation\n    skip: int = 1,  # Animate every &lt;skip&gt; frames of the optimization\n    dpi: int = 192,  # DPI of each frame of the animation\n    fps: int = 30,  # FPS of the animation\n):\n    \"\"\"Animate the trajectory of iterative optimization.\"\"\"\n\n    # Initialize the renderer\n    run = torch.load(inpath, weights_only=False)\n    drr = initialize_drr(**run[\"drr\"])\n    gt, *_ = read_xray(**run[\"xray\"])\n    scales = _parse_scales(\n        run[\"optimization\"][\"scales\"], run[\"xray\"][\"crop\"], run[\"drr\"][\"height\"]\n    )\n\n    # Render all DRRs\n    drrs = render(drr, gt, scales, run, skip)\n\n    # Generate the animation\n    frames = plot(drrs, dpi)\n    imwrite(outpath, frames, fps=fps)\n</code></pre>"},{"location":"reference/xvr/visualization/viz2d/","title":"viz2d","text":""},{"location":"reference/xvr/visualization/viz2d/#xvr.visualization.viz2d","title":"xvr.visualization.viz2d","text":""}]}